{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98479d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0. 1.], y=[1. 0. 0. ... 0. 0. 0.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "image/png": "\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "seed = 246\n",
    "\n",
    "# model-compile parameter sets\n",
    "model_metrics = 'acc'\n",
    "epochs = 500\n",
    "batchs = 64\n",
    "splits = 0.2\n",
    "lr        = 3e-4\n",
    "input_dim = 3\n",
    "opt = Adam(learning_rate=lr,decay=3e-4/200)\n",
    "\n",
    "concatenated_df=pd.read_csv(\"oriI_extraFeatures_Geo.csv\")\n",
    "XY = concatenated_df.values\n",
    "for i in range(10):\n",
    "    np.random.shuffle(XY)\n",
    "X = XY[:,[0,2,3]]\n",
    "Y = XY[:,[5]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=splits, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "inputShape=(input_dim,)\n",
    "model.add(Input(shape=inputShape))\n",
    "x = Dense(10,activation=\"relu\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(model.output)\n",
    "x = Dense(5,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "# x = Dense(5,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "x = Dense(1,activation =\"sigmoid\", kernel_initializer=\"RandomNormal\", bias_initializer=\"RandomNormal\")(x)\n",
    "model = Model(inputs=[model.input],outputs=x)\n",
    "model.compile(loss=\"mse\",optimizer=opt,metrics=['acc'])\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = dict(zip(np.unique(y_train),class_weights))\n",
    "\n",
    "plot_model(model,to_file='FeaturesPlots/model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f051155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10500/10500 [==============================] - 11s 989us/step - loss: 0.1457 - acc: 0.7797 - val_loss: 0.1149 - val_acc: 0.8334\n",
      "Epoch 2/500\n",
      "10500/10500 [==============================] - 10s 989us/step - loss: 0.1021 - acc: 0.8410 - val_loss: 0.1071 - val_acc: 0.8438\n",
      "Epoch 3/500\n",
      "10500/10500 [==============================] - 10s 986us/step - loss: 0.0965 - acc: 0.8524 - val_loss: 0.1113 - val_acc: 0.8399\n",
      "Epoch 4/500\n",
      "10500/10500 [==============================] - 10s 997us/step - loss: 0.0961 - acc: 0.8544 - val_loss: 0.1078 - val_acc: 0.8535\n",
      "Epoch 5/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0960 - acc: 0.8540 - val_loss: 0.1073 - val_acc: 0.8543\n",
      "Epoch 6/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0960 - acc: 0.8534 - val_loss: 0.1042 - val_acc: 0.8571\n",
      "Epoch 7/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8533 - val_loss: 0.1120 - val_acc: 0.8461\n",
      "Epoch 8/500\n",
      "10500/10500 [==============================] - 12s 1ms/step - loss: 0.0959 - acc: 0.8526 - val_loss: 0.1081 - val_acc: 0.8521\n",
      "Epoch 9/500\n",
      "10500/10500 [==============================] - 12s 1ms/step - loss: 0.0959 - acc: 0.8526 - val_loss: 0.1107 - val_acc: 0.8461\n",
      "Epoch 10/500\n",
      "10500/10500 [==============================] - 12s 1ms/step - loss: 0.0959 - acc: 0.8523 - val_loss: 0.1081 - val_acc: 0.8520\n",
      "Epoch 11/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8522 - val_loss: 0.1054 - val_acc: 0.8545\n",
      "Epoch 12/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8522 - val_loss: 0.1058 - val_acc: 0.8542\n",
      "Epoch 13/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8519 - val_loss: 0.1060 - val_acc: 0.8538\n",
      "Epoch 14/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8519 - val_loss: 0.1080 - val_acc: 0.8510\n",
      "Epoch 15/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0959 - acc: 0.8520 - val_loss: 0.1067 - val_acc: 0.8530\n",
      "Epoch 16/500\n",
      "10500/10500 [==============================] - 10s 908us/step - loss: 0.0959 - acc: 0.8519 - val_loss: 0.1062 - val_acc: 0.8534\n",
      "Epoch 17/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1087 - val_acc: 0.8508\n",
      "Epoch 18/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0958 - acc: 0.8518 - val_loss: 0.1087 - val_acc: 0.8508\n",
      "Epoch 19/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0958 - acc: 0.8517 - val_loss: 0.1071 - val_acc: 0.8524\n",
      "Epoch 20/500\n",
      "10500/10500 [==============================] - 9s 875us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1107 - val_acc: 0.8494\n",
      "Epoch 21/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0958 - acc: 0.8517 - val_loss: 0.1048 - val_acc: 0.8550\n",
      "Epoch 22/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0958 - acc: 0.8516 - val_loss: 0.1124 - val_acc: 0.8335\n",
      "Epoch 23/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0958 - acc: 0.8516 - val_loss: 0.1070 - val_acc: 0.8520\n",
      "Epoch 24/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0958 - acc: 0.8518 - val_loss: 0.1045 - val_acc: 0.8550\n",
      "Epoch 25/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0958 - acc: 0.8513 - val_loss: 0.1061 - val_acc: 0.8532\n",
      "Epoch 26/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0958 - acc: 0.8520 - val_loss: 0.1057 - val_acc: 0.8534\n",
      "Epoch 27/500\n",
      "10500/10500 [==============================] - 10s 911us/step - loss: 0.0958 - acc: 0.8515 - val_loss: 0.1025 - val_acc: 0.8572\n",
      "Epoch 28/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1053 - val_acc: 0.8536\n",
      "Epoch 29/500\n",
      "10500/10500 [==============================] - 10s 973us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1118 - val_acc: 0.8452\n",
      "Epoch 30/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0958 - acc: 0.8514 - val_loss: 0.1038 - val_acc: 0.8556\n",
      "Epoch 31/500\n",
      "10500/10500 [==============================] - 10s 947us/step - loss: 0.0958 - acc: 0.8522 - val_loss: 0.1038 - val_acc: 0.8554\n",
      "Epoch 32/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1076 - val_acc: 0.8520\n",
      "Epoch 33/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0958 - acc: 0.8516 - val_loss: 0.1084 - val_acc: 0.8505\n",
      "Epoch 34/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0958 - acc: 0.8520 - val_loss: 0.1045 - val_acc: 0.8551\n",
      "Epoch 35/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0958 - acc: 0.8515 - val_loss: 0.1067 - val_acc: 0.8497\n",
      "Epoch 36/500\n",
      "10500/10500 [==============================] - 10s 908us/step - loss: 0.0958 - acc: 0.8517 - val_loss: 0.1046 - val_acc: 0.8544\n",
      "Epoch 37/500\n",
      "10500/10500 [==============================] - 10s 908us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1072 - val_acc: 0.8520\n",
      "Epoch 38/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1099 - val_acc: 0.8461\n",
      "Epoch 39/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0958 - acc: 0.8519 - val_loss: 0.1060 - val_acc: 0.8534\n",
      "Epoch 40/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0957 - acc: 0.8520 - val_loss: 0.1097 - val_acc: 0.8473\n",
      "Epoch 41/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0958 - acc: 0.8515 - val_loss: 0.1038 - val_acc: 0.8554\n",
      "Epoch 42/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0958 - acc: 0.8518 - val_loss: 0.1058 - val_acc: 0.8534\n",
      "Epoch 43/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1030 - val_acc: 0.8561\n",
      "Epoch 44/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0957 - acc: 0.8519 - val_loss: 0.1034 - val_acc: 0.8555\n",
      "Epoch 45/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1064 - val_acc: 0.8526\n",
      "Epoch 46/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1081 - val_acc: 0.8518\n",
      "Epoch 47/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0958 - acc: 0.8521 - val_loss: 0.1061 - val_acc: 0.8534\n",
      "Epoch 48/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1046 - val_acc: 0.8546\n",
      "Epoch 49/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1029 - val_acc: 0.8563\n",
      "Epoch 50/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1027 - val_acc: 0.8568\n",
      "Epoch 51/500\n",
      "10500/10500 [==============================] - 10s 909us/step - loss: 0.0957 - acc: 0.8521 - val_loss: 0.1130 - val_acc: 0.8429\n",
      "Epoch 52/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0957 - acc: 0.8515 - val_loss: 0.1085 - val_acc: 0.8481\n",
      "Epoch 53/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1066 - val_acc: 0.8531\n",
      "Epoch 54/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1059 - val_acc: 0.8534\n",
      "Epoch 55/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1065 - val_acc: 0.8533\n",
      "Epoch 56/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0957 - acc: 0.8522 - val_loss: 0.1094 - val_acc: 0.8472\n",
      "Epoch 57/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1129 - val_acc: 0.8431\n",
      "Epoch 58/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1069 - val_acc: 0.8530\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1115 - val_acc: 0.8450\n",
      "Epoch 60/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1084 - val_acc: 0.8513\n",
      "Epoch 61/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0957 - acc: 0.8515 - val_loss: 0.1026 - val_acc: 0.8559\n",
      "Epoch 62/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1014 - val_acc: 0.8577\n",
      "Epoch 63/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1069 - val_acc: 0.8529\n",
      "Epoch 64/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1074 - val_acc: 0.8520\n",
      "Epoch 65/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0957 - acc: 0.8518 - val_loss: 0.1074 - val_acc: 0.8515\n",
      "Epoch 66/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0957 - acc: 0.8521 - val_loss: 0.1128 - val_acc: 0.8441\n",
      "Epoch 67/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0957 - acc: 0.8519 - val_loss: 0.1101 - val_acc: 0.8461\n",
      "Epoch 68/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0957 - acc: 0.8515 - val_loss: 0.1036 - val_acc: 0.8555\n",
      "Epoch 69/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1056 - val_acc: 0.8536\n",
      "Epoch 70/500\n",
      "10500/10500 [==============================] - 10s 906us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1046 - val_acc: 0.8544\n",
      "Epoch 71/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0957 - acc: 0.8520 - val_loss: 0.1056 - val_acc: 0.8543\n",
      "Epoch 72/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1097 - val_acc: 0.8466\n",
      "Epoch 73/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1067 - val_acc: 0.8522\n",
      "Epoch 74/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0957 - acc: 0.8514 - val_loss: 0.1047 - val_acc: 0.8539\n",
      "Epoch 75/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0957 - acc: 0.8519 - val_loss: 0.1069 - val_acc: 0.8519\n",
      "Epoch 76/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1087 - val_acc: 0.8481\n",
      "Epoch 77/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1059 - val_acc: 0.8539\n",
      "Epoch 78/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0957 - acc: 0.8515 - val_loss: 0.1018 - val_acc: 0.8584\n",
      "Epoch 79/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1070 - val_acc: 0.8520\n",
      "Epoch 80/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0957 - acc: 0.8517 - val_loss: 0.1081 - val_acc: 0.8514\n",
      "Epoch 81/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0957 - acc: 0.8516 - val_loss: 0.1086 - val_acc: 0.8501\n",
      "Epoch 82/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0956 - acc: 0.8518 - val_loss: 0.1060 - val_acc: 0.8530\n",
      "Epoch 83/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0957 - acc: 0.8514 - val_loss: 0.1045 - val_acc: 0.8544\n",
      "Epoch 84/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0956 - acc: 0.8517 - val_loss: 0.1063 - val_acc: 0.8523\n",
      "Epoch 85/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1037 - val_acc: 0.8551\n",
      "Epoch 86/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0956 - acc: 0.8515 - val_loss: 0.1029 - val_acc: 0.8554\n",
      "Epoch 87/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0956 - acc: 0.8516 - val_loss: 0.1091 - val_acc: 0.8497\n",
      "Epoch 88/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0956 - acc: 0.8517 - val_loss: 0.1110 - val_acc: 0.8453\n",
      "Epoch 89/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0956 - acc: 0.8517 - val_loss: 0.1075 - val_acc: 0.8515\n",
      "Epoch 90/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0956 - acc: 0.8516 - val_loss: 0.1115 - val_acc: 0.8449\n",
      "Epoch 91/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1080 - val_acc: 0.8510\n",
      "Epoch 92/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0956 - acc: 0.8517 - val_loss: 0.1053 - val_acc: 0.8541\n",
      "Epoch 93/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0956 - acc: 0.8516 - val_loss: 0.1100 - val_acc: 0.8455\n",
      "Epoch 94/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1070 - val_acc: 0.8486\n",
      "Epoch 95/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0956 - acc: 0.8515 - val_loss: 0.1064 - val_acc: 0.8519\n",
      "Epoch 96/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1038 - val_acc: 0.8551\n",
      "Epoch 97/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1063 - val_acc: 0.8522\n",
      "Epoch 98/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1110 - val_acc: 0.8452\n",
      "Epoch 99/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1035 - val_acc: 0.8554\n",
      "Epoch 100/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1096 - val_acc: 0.8458\n",
      "Epoch 101/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0956 - acc: 0.8514 - val_loss: 0.1088 - val_acc: 0.8472\n",
      "Epoch 102/500\n",
      "10500/10500 [==============================] - 11s 1ms/step - loss: 0.0956 - acc: 0.8511 - val_loss: 0.1087 - val_acc: 0.8466\n",
      "Epoch 103/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0956 - acc: 0.8511 - val_loss: 0.1030 - val_acc: 0.8555\n",
      "Epoch 104/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0956 - acc: 0.8511 - val_loss: 0.1080 - val_acc: 0.8480\n",
      "Epoch 105/500\n",
      "10500/10500 [==============================] - 10s 963us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1075 - val_acc: 0.8515\n",
      "Epoch 106/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0956 - acc: 0.8515 - val_loss: 0.1072 - val_acc: 0.8482\n",
      "Epoch 107/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0956 - acc: 0.8509 - val_loss: 0.1073 - val_acc: 0.8515\n",
      "Epoch 108/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0956 - acc: 0.8512 - val_loss: 0.1032 - val_acc: 0.8553\n",
      "Epoch 109/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1067 - val_acc: 0.8519\n",
      "Epoch 110/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0956 - acc: 0.8513 - val_loss: 0.1081 - val_acc: 0.8473\n",
      "Epoch 111/500\n",
      "10500/10500 [==============================] - 10s 923us/step - loss: 0.0956 - acc: 0.8510 - val_loss: 0.1073 - val_acc: 0.8513\n",
      "Epoch 112/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0956 - acc: 0.8511 - val_loss: 0.1088 - val_acc: 0.8469\n",
      "Epoch 113/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0956 - acc: 0.8509 - val_loss: 0.1070 - val_acc: 0.8487\n",
      "Epoch 114/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0956 - acc: 0.8508 - val_loss: 0.1044 - val_acc: 0.8542\n",
      "Epoch 115/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0956 - acc: 0.8508 - val_loss: 0.1059 - val_acc: 0.8521\n",
      "Epoch 116/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0956 - acc: 0.8508 - val_loss: 0.1030 - val_acc: 0.8554\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 901us/step - loss: 0.0956 - acc: 0.8508 - val_loss: 0.1083 - val_acc: 0.8469\n",
      "Epoch 118/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0956 - acc: 0.8506 - val_loss: 0.1053 - val_acc: 0.8531\n",
      "Epoch 119/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0956 - acc: 0.8509 - val_loss: 0.1078 - val_acc: 0.8481\n",
      "Epoch 120/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0956 - acc: 0.8508 - val_loss: 0.1049 - val_acc: 0.8534\n",
      "Epoch 121/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0955 - acc: 0.8507 - val_loss: 0.1011 - val_acc: 0.8579\n",
      "Epoch 122/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0955 - acc: 0.8509 - val_loss: 0.1084 - val_acc: 0.8473\n",
      "Epoch 123/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0955 - acc: 0.8506 - val_loss: 0.1115 - val_acc: 0.8449\n",
      "Epoch 124/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0955 - acc: 0.8503 - val_loss: 0.1075 - val_acc: 0.8513\n",
      "Epoch 125/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0955 - acc: 0.8508 - val_loss: 0.1052 - val_acc: 0.8533\n",
      "Epoch 126/500\n",
      "10500/10500 [==============================] - 10s 907us/step - loss: 0.0955 - acc: 0.8507 - val_loss: 0.1102 - val_acc: 0.8455\n",
      "Epoch 127/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0955 - acc: 0.8504 - val_loss: 0.1109 - val_acc: 0.8450\n",
      "Epoch 128/500\n",
      "10500/10500 [==============================] - 10s 907us/step - loss: 0.0955 - acc: 0.8506 - val_loss: 0.1062 - val_acc: 0.8487\n",
      "Epoch 129/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0955 - acc: 0.8505 - val_loss: 0.1069 - val_acc: 0.8486\n",
      "Epoch 130/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0955 - acc: 0.8503 - val_loss: 0.1076 - val_acc: 0.8480\n",
      "Epoch 131/500\n",
      "10500/10500 [==============================] - 10s 916us/step - loss: 0.0955 - acc: 0.8502 - val_loss: 0.1023 - val_acc: 0.8561\n",
      "Epoch 132/500\n",
      "10500/10500 [==============================] - 10s 916us/step - loss: 0.0955 - acc: 0.8508 - val_loss: 0.1074 - val_acc: 0.8481\n",
      "Epoch 133/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0955 - acc: 0.8501 - val_loss: 0.1065 - val_acc: 0.8515\n",
      "Epoch 134/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0955 - acc: 0.8504 - val_loss: 0.1046 - val_acc: 0.8534\n",
      "Epoch 135/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0955 - acc: 0.8502 - val_loss: 0.1069 - val_acc: 0.8483\n",
      "Epoch 136/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0955 - acc: 0.8504 - val_loss: 0.1047 - val_acc: 0.8506\n",
      "Epoch 137/500\n",
      "10500/10500 [==============================] - 10s 917us/step - loss: 0.0955 - acc: 0.8500 - val_loss: 0.1052 - val_acc: 0.8524\n",
      "Epoch 138/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0955 - acc: 0.8503 - val_loss: 0.1070 - val_acc: 0.8482\n",
      "Epoch 139/500\n",
      "10500/10500 [==============================] - 10s 910us/step - loss: 0.0955 - acc: 0.8499 - val_loss: 0.1040 - val_acc: 0.8542\n",
      "Epoch 140/500\n",
      "10500/10500 [==============================] - 10s 917us/step - loss: 0.0955 - acc: 0.8503 - val_loss: 0.1045 - val_acc: 0.8534\n",
      "Epoch 141/500\n",
      "10500/10500 [==============================] - 10s 918us/step - loss: 0.0955 - acc: 0.8499 - val_loss: 0.1035 - val_acc: 0.8544\n",
      "Epoch 142/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0955 - acc: 0.8501 - val_loss: 0.1061 - val_acc: 0.8487\n",
      "Epoch 143/500\n",
      "10500/10500 [==============================] - 10s 917us/step - loss: 0.0955 - acc: 0.8504 - val_loss: 0.1077 - val_acc: 0.8478\n",
      "Epoch 144/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0955 - acc: 0.8496 - val_loss: 0.1077 - val_acc: 0.8473\n",
      "Epoch 145/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0955 - acc: 0.8500 - val_loss: 0.1076 - val_acc: 0.8473\n",
      "Epoch 146/500\n",
      "10500/10500 [==============================] - 10s 908us/step - loss: 0.0955 - acc: 0.8499 - val_loss: 0.1109 - val_acc: 0.8441\n",
      "Epoch 147/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0955 - acc: 0.8497 - val_loss: 0.1014 - val_acc: 0.8570\n",
      "Epoch 148/500\n",
      "10500/10500 [==============================] - 9s 904us/step - loss: 0.0955 - acc: 0.8501 - val_loss: 0.1072 - val_acc: 0.8473\n",
      "Epoch 149/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0955 - acc: 0.8500 - val_loss: 0.1050 - val_acc: 0.8497\n",
      "Epoch 150/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0954 - acc: 0.8496 - val_loss: 0.1067 - val_acc: 0.8483\n",
      "Epoch 151/500\n",
      "10500/10500 [==============================] - 9s 904us/step - loss: 0.0954 - acc: 0.8500 - val_loss: 0.1093 - val_acc: 0.8455\n",
      "Epoch 152/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0954 - acc: 0.8495 - val_loss: 0.1063 - val_acc: 0.8486\n",
      "Epoch 153/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0954 - acc: 0.8498 - val_loss: 0.1112 - val_acc: 0.8436\n",
      "Epoch 154/500\n",
      "10500/10500 [==============================] - 9s 901us/step - loss: 0.0954 - acc: 0.8492 - val_loss: 0.1045 - val_acc: 0.8534\n",
      "Epoch 155/500\n",
      "10500/10500 [==============================] - 9s 901us/step - loss: 0.0954 - acc: 0.8499 - val_loss: 0.1072 - val_acc: 0.8478\n",
      "Epoch 156/500\n",
      "10500/10500 [==============================] - 10s 913us/step - loss: 0.0954 - acc: 0.8494 - val_loss: 0.1048 - val_acc: 0.8534\n",
      "Epoch 157/500\n",
      "10500/10500 [==============================] - 10s 907us/step - loss: 0.0954 - acc: 0.8498 - val_loss: 0.1069 - val_acc: 0.8478\n",
      "Epoch 158/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0954 - acc: 0.8496 - val_loss: 0.1058 - val_acc: 0.8487\n",
      "Epoch 159/500\n",
      "10500/10500 [==============================] - 9s 901us/step - loss: 0.0954 - acc: 0.8496 - val_loss: 0.1082 - val_acc: 0.8470\n",
      "Epoch 160/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0954 - acc: 0.8494 - val_loss: 0.1069 - val_acc: 0.8482\n",
      "Epoch 161/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0954 - acc: 0.8494 - val_loss: 0.1035 - val_acc: 0.8537\n",
      "Epoch 162/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0954 - acc: 0.8501 - val_loss: 0.1091 - val_acc: 0.8458\n",
      "Epoch 163/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0954 - acc: 0.8495 - val_loss: 0.1078 - val_acc: 0.8472\n",
      "Epoch 164/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0954 - acc: 0.8498 - val_loss: 0.1095 - val_acc: 0.8442\n",
      "Epoch 165/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0954 - acc: 0.8493 - val_loss: 0.1060 - val_acc: 0.8488\n",
      "Epoch 166/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0954 - acc: 0.8494 - val_loss: 0.1062 - val_acc: 0.8483\n",
      "Epoch 167/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0954 - acc: 0.8495 - val_loss: 0.1045 - val_acc: 0.8534\n",
      "Epoch 168/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0954 - acc: 0.8492 - val_loss: 0.1046 - val_acc: 0.8497\n",
      "Epoch 169/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0953 - acc: 0.8493 - val_loss: 0.1012 - val_acc: 0.8567\n",
      "Epoch 170/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0953 - acc: 0.8495 - val_loss: 0.1049 - val_acc: 0.8497\n",
      "Epoch 171/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0953 - acc: 0.8496 - val_loss: 0.1089 - val_acc: 0.8467\n",
      "Epoch 172/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0953 - acc: 0.8495 - val_loss: 0.1073 - val_acc: 0.8472\n",
      "Epoch 173/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0953 - acc: 0.8494 - val_loss: 0.1100 - val_acc: 0.8445\n",
      "Epoch 174/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0953 - acc: 0.8494 - val_loss: 0.1094 - val_acc: 0.8454\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0953 - acc: 0.8492 - val_loss: 0.1032 - val_acc: 0.8542\n",
      "Epoch 176/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0953 - acc: 0.8496 - val_loss: 0.1078 - val_acc: 0.8470\n",
      "Epoch 177/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0953 - acc: 0.8492 - val_loss: 0.1066 - val_acc: 0.8475\n",
      "Epoch 178/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0953 - acc: 0.8492 - val_loss: 0.1058 - val_acc: 0.8487\n",
      "Epoch 179/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0953 - acc: 0.8495 - val_loss: 0.1069 - val_acc: 0.8475\n",
      "Epoch 180/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0953 - acc: 0.8491 - val_loss: 0.1032 - val_acc: 0.8538\n",
      "Epoch 181/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0953 - acc: 0.8495 - val_loss: 0.1070 - val_acc: 0.8473\n",
      "Epoch 182/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0953 - acc: 0.8496 - val_loss: 0.1089 - val_acc: 0.8456\n",
      "Epoch 183/500\n",
      "10500/10500 [==============================] - 10s 905us/step - loss: 0.0953 - acc: 0.8492 - val_loss: 0.1005 - val_acc: 0.8569\n",
      "Epoch 184/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0953 - acc: 0.8493 - val_loss: 0.1060 - val_acc: 0.8478\n",
      "Epoch 185/500\n",
      "10500/10500 [==============================] - 10s 909us/step - loss: 0.0952 - acc: 0.8491 - val_loss: 0.1034 - val_acc: 0.8534\n",
      "Epoch 186/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0952 - acc: 0.8497 - val_loss: 0.1052 - val_acc: 0.8487\n",
      "Epoch 187/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0952 - acc: 0.8490 - val_loss: 0.1051 - val_acc: 0.8519\n",
      "Epoch 188/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0952 - acc: 0.8497 - val_loss: 0.1091 - val_acc: 0.8454\n",
      "Epoch 189/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0952 - acc: 0.8492 - val_loss: 0.1067 - val_acc: 0.8473\n",
      "Epoch 190/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0952 - acc: 0.8493 - val_loss: 0.1049 - val_acc: 0.8487\n",
      "Epoch 191/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0952 - acc: 0.8495 - val_loss: 0.1078 - val_acc: 0.8459\n",
      "Epoch 192/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0952 - acc: 0.8496 - val_loss: 0.1035 - val_acc: 0.8534\n",
      "Epoch 193/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0952 - acc: 0.8496 - val_loss: 0.1063 - val_acc: 0.8473\n",
      "Epoch 194/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0952 - acc: 0.8492 - val_loss: 0.1047 - val_acc: 0.8487\n",
      "Epoch 195/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0952 - acc: 0.8495 - val_loss: 0.1061 - val_acc: 0.8475\n",
      "Epoch 196/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0952 - acc: 0.8496 - val_loss: 0.1075 - val_acc: 0.8470\n",
      "Epoch 197/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0952 - acc: 0.8492 - val_loss: 0.1061 - val_acc: 0.8475\n",
      "Epoch 198/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0952 - acc: 0.8495 - val_loss: 0.1041 - val_acc: 0.8530\n",
      "Epoch 199/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0951 - acc: 0.8494 - val_loss: 0.1050 - val_acc: 0.8486\n",
      "Epoch 200/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0951 - acc: 0.8494 - val_loss: 0.1071 - val_acc: 0.8470\n",
      "Epoch 201/500\n",
      "10500/10500 [==============================] - 10s 944us/step - loss: 0.0951 - acc: 0.8493 - val_loss: 0.1073 - val_acc: 0.8469\n",
      "Epoch 202/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0951 - acc: 0.8490 - val_loss: 0.1023 - val_acc: 0.8546\n",
      "Epoch 203/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0951 - acc: 0.8495 - val_loss: 0.1053 - val_acc: 0.8485\n",
      "Epoch 204/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0951 - acc: 0.8491 - val_loss: 0.1068 - val_acc: 0.8473\n",
      "Epoch 205/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0951 - acc: 0.8493 - val_loss: 0.1066 - val_acc: 0.8473\n",
      "Epoch 206/500\n",
      "10500/10500 [==============================] - 9s 901us/step - loss: 0.0951 - acc: 0.8499 - val_loss: 0.1080 - val_acc: 0.8458\n",
      "Epoch 207/500\n",
      "10500/10500 [==============================] - 10s 923us/step - loss: 0.0951 - acc: 0.8492 - val_loss: 0.1061 - val_acc: 0.8470\n",
      "Epoch 208/500\n",
      "10500/10500 [==============================] - 10s 919us/step - loss: 0.0951 - acc: 0.8496 - val_loss: 0.1066 - val_acc: 0.8473\n",
      "Epoch 209/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0951 - acc: 0.8494 - val_loss: 0.1030 - val_acc: 0.8542\n",
      "Epoch 210/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0951 - acc: 0.8497 - val_loss: 0.1043 - val_acc: 0.8518\n",
      "Epoch 211/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0951 - acc: 0.8498 - val_loss: 0.1098 - val_acc: 0.8436\n",
      "Epoch 212/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0951 - acc: 0.8489 - val_loss: 0.1039 - val_acc: 0.8523\n",
      "Epoch 213/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0951 - acc: 0.8496 - val_loss: 0.1071 - val_acc: 0.8462\n",
      "Epoch 214/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8497 - val_loss: 0.1057 - val_acc: 0.8475\n",
      "Epoch 215/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0950 - acc: 0.8493 - val_loss: 0.1052 - val_acc: 0.8483\n",
      "Epoch 216/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8494 - val_loss: 0.1055 - val_acc: 0.8481\n",
      "Epoch 217/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0950 - acc: 0.8493 - val_loss: 0.1075 - val_acc: 0.8461\n",
      "Epoch 218/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0950 - acc: 0.8499 - val_loss: 0.1059 - val_acc: 0.8464\n",
      "Epoch 219/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0950 - acc: 0.8493 - val_loss: 0.1061 - val_acc: 0.8470\n",
      "Epoch 220/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0950 - acc: 0.8496 - val_loss: 0.1088 - val_acc: 0.8450\n",
      "Epoch 221/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0950 - acc: 0.8489 - val_loss: 0.1033 - val_acc: 0.8524\n",
      "Epoch 222/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0950 - acc: 0.8494 - val_loss: 0.1046 - val_acc: 0.8518\n",
      "Epoch 223/500\n",
      "10500/10500 [==============================] - 9s 875us/step - loss: 0.0950 - acc: 0.8494 - val_loss: 0.1029 - val_acc: 0.8532\n",
      "Epoch 224/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8494 - val_loss: 0.1048 - val_acc: 0.8486\n",
      "Epoch 225/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8494 - val_loss: 0.1036 - val_acc: 0.8524\n",
      "Epoch 226/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0950 - acc: 0.8492 - val_loss: 0.1062 - val_acc: 0.8470\n",
      "Epoch 227/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0950 - acc: 0.8496 - val_loss: 0.1083 - val_acc: 0.8453\n",
      "Epoch 228/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8491 - val_loss: 0.1083 - val_acc: 0.8438\n",
      "Epoch 229/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0950 - acc: 0.8492 - val_loss: 0.1059 - val_acc: 0.8470\n",
      "Epoch 230/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8491 - val_loss: 0.1052 - val_acc: 0.8503\n",
      "Epoch 231/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8492 - val_loss: 0.1062 - val_acc: 0.8470\n",
      "Epoch 232/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8493 - val_loss: 0.1059 - val_acc: 0.8470\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0950 - acc: 0.8489 - val_loss: 0.1051 - val_acc: 0.8470\n",
      "Epoch 234/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8495 - val_loss: 0.1069 - val_acc: 0.8461\n",
      "Epoch 235/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8492 - val_loss: 0.1053 - val_acc: 0.8472\n",
      "Epoch 236/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8489 - val_loss: 0.1047 - val_acc: 0.8483\n",
      "Epoch 237/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0950 - acc: 0.8489 - val_loss: 0.1073 - val_acc: 0.8456\n",
      "Epoch 238/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0950 - acc: 0.8486 - val_loss: 0.1023 - val_acc: 0.8532\n",
      "Epoch 239/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0950 - acc: 0.8491 - val_loss: 0.1062 - val_acc: 0.8470\n",
      "Epoch 240/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8490 - val_loss: 0.1059 - val_acc: 0.8470\n",
      "Epoch 241/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8485 - val_loss: 0.1057 - val_acc: 0.8470\n",
      "Epoch 242/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8484 - val_loss: 0.1031 - val_acc: 0.8532\n",
      "Epoch 243/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8486 - val_loss: 0.1034 - val_acc: 0.8524\n",
      "Epoch 244/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8488 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 245/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8487 - val_loss: 0.1053 - val_acc: 0.8471\n",
      "Epoch 246/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8491 - val_loss: 0.1056 - val_acc: 0.8470\n",
      "Epoch 247/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0950 - acc: 0.8483 - val_loss: 0.1043 - val_acc: 0.8521\n",
      "Epoch 248/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0950 - acc: 0.8490 - val_loss: 0.1080 - val_acc: 0.8443\n",
      "Epoch 249/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0950 - acc: 0.8485 - val_loss: 0.1037 - val_acc: 0.8523\n",
      "Epoch 250/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0950 - acc: 0.8488 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 251/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8487 - val_loss: 0.1054 - val_acc: 0.8470\n",
      "Epoch 252/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8485 - val_loss: 0.1084 - val_acc: 0.8436\n",
      "Epoch 253/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8485 - val_loss: 0.1065 - val_acc: 0.8462\n",
      "Epoch 254/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0950 - acc: 0.8483 - val_loss: 0.1047 - val_acc: 0.8472\n",
      "Epoch 255/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0950 - acc: 0.8481 - val_loss: 0.1068 - val_acc: 0.8461\n",
      "Epoch 256/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0950 - acc: 0.8484 - val_loss: 0.1057 - val_acc: 0.8472\n",
      "Epoch 257/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0950 - acc: 0.8481 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 258/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0950 - acc: 0.8480 - val_loss: 0.1052 - val_acc: 0.8470\n",
      "Epoch 259/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0950 - acc: 0.8483 - val_loss: 0.1045 - val_acc: 0.8473\n",
      "Epoch 260/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8485 - val_loss: 0.1030 - val_acc: 0.8532\n",
      "Epoch 261/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8488 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 262/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8483 - val_loss: 0.1053 - val_acc: 0.8473\n",
      "Epoch 263/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8483 - val_loss: 0.1063 - val_acc: 0.8462\n",
      "Epoch 264/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8481 - val_loss: 0.1043 - val_acc: 0.8478\n",
      "Epoch 265/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1058 - val_acc: 0.8470\n",
      "Epoch 266/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8484 - val_loss: 0.1026 - val_acc: 0.8526\n",
      "Epoch 267/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8487 - val_loss: 0.1066 - val_acc: 0.8462\n",
      "Epoch 268/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1073 - val_acc: 0.8443\n",
      "Epoch 269/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1047 - val_acc: 0.8472\n",
      "Epoch 270/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8481 - val_loss: 0.1068 - val_acc: 0.8462\n",
      "Epoch 271/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1043 - val_acc: 0.8478\n",
      "Epoch 272/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8482 - val_loss: 0.1066 - val_acc: 0.8462\n",
      "Epoch 273/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1034 - val_acc: 0.8518\n",
      "Epoch 274/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8485 - val_loss: 0.1072 - val_acc: 0.8447\n",
      "Epoch 275/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1058 - val_acc: 0.8470\n",
      "Epoch 276/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1026 - val_acc: 0.8526\n",
      "Epoch 277/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1047 - val_acc: 0.8472\n",
      "Epoch 278/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8481 - val_loss: 0.1067 - val_acc: 0.8462\n",
      "Epoch 279/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1051 - val_acc: 0.8472\n",
      "Epoch 280/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 281/500\n",
      "10500/10500 [==============================] - 9s 875us/step - loss: 0.0949 - acc: 0.8481 - val_loss: 0.1056 - val_acc: 0.8472\n",
      "Epoch 282/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1080 - val_acc: 0.8439\n",
      "Epoch 283/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1060 - val_acc: 0.8464\n",
      "Epoch 284/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1092 - val_acc: 0.8431\n",
      "Epoch 285/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1067 - val_acc: 0.8462\n",
      "Epoch 286/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1056 - val_acc: 0.8470\n",
      "Epoch 287/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1064 - val_acc: 0.8462\n",
      "Epoch 288/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8477 - val_loss: 0.1040 - val_acc: 0.8510\n",
      "Epoch 289/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1042 - val_acc: 0.8476\n",
      "Epoch 290/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1013 - val_acc: 0.8534\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1031 - val_acc: 0.8524\n",
      "Epoch 292/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1031 - val_acc: 0.8524\n",
      "Epoch 293/500\n",
      "10500/10500 [==============================] - 9s 875us/step - loss: 0.0949 - acc: 0.8481 - val_loss: 0.1068 - val_acc: 0.8443\n",
      "Epoch 294/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8482 - val_loss: 0.1045 - val_acc: 0.8472\n",
      "Epoch 295/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1075 - val_acc: 0.8443\n",
      "Epoch 296/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8475 - val_loss: 0.1049 - val_acc: 0.8473\n",
      "Epoch 297/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8482 - val_loss: 0.1081 - val_acc: 0.8434\n",
      "Epoch 298/500\n",
      "10500/10500 [==============================] - 10s 938us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1035 - val_acc: 0.8492\n",
      "Epoch 299/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8475 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 300/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1070 - val_acc: 0.8448\n",
      "Epoch 301/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8475 - val_loss: 0.1053 - val_acc: 0.8472\n",
      "Epoch 302/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8477 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 303/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 304/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8480 - val_loss: 0.1026 - val_acc: 0.8526\n",
      "Epoch 305/500\n",
      "10500/10500 [==============================] - 9s 875us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1033 - val_acc: 0.8492\n",
      "Epoch 306/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1056 - val_acc: 0.8470\n",
      "Epoch 307/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1060 - val_acc: 0.8464\n",
      "Epoch 308/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1058 - val_acc: 0.8462\n",
      "Epoch 309/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8477 - val_loss: 0.1053 - val_acc: 0.8472\n",
      "Epoch 310/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 311/500\n",
      "10500/10500 [==============================] - 10s 924us/step - loss: 0.0949 - acc: 0.8476 - val_loss: 0.1074 - val_acc: 0.8443\n",
      "Epoch 312/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1033 - val_acc: 0.8492\n",
      "Epoch 313/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8479 - val_loss: 0.1083 - val_acc: 0.8434\n",
      "Epoch 314/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1033 - val_acc: 0.8492\n",
      "Epoch 315/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 316/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1070 - val_acc: 0.8443\n",
      "Epoch 317/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1055 - val_acc: 0.8472\n",
      "Epoch 318/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1029 - val_acc: 0.8524\n",
      "Epoch 319/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 320/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 321/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1055 - val_acc: 0.8470\n",
      "Epoch 322/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1050 - val_acc: 0.8472\n",
      "Epoch 323/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1071 - val_acc: 0.8443\n",
      "Epoch 324/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1056 - val_acc: 0.8472\n",
      "Epoch 325/500\n",
      "10500/10500 [==============================] - 10s 912us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1056 - val_acc: 0.8470\n",
      "Epoch 326/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1046 - val_acc: 0.8473\n",
      "Epoch 327/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1050 - val_acc: 0.8472\n",
      "Epoch 328/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8478 - val_loss: 0.1074 - val_acc: 0.8440\n",
      "Epoch 329/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1064 - val_acc: 0.8462\n",
      "Epoch 330/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1076 - val_acc: 0.8443\n",
      "Epoch 331/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1063 - val_acc: 0.8462\n",
      "Epoch 332/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1038 - val_acc: 0.8478\n",
      "Epoch 333/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1034 - val_acc: 0.8492\n",
      "Epoch 334/500\n",
      "10500/10500 [==============================] - 10s 913us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1037 - val_acc: 0.8478\n",
      "Epoch 335/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1053 - val_acc: 0.8472\n",
      "Epoch 336/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1050 - val_acc: 0.8472\n",
      "Epoch 337/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1038 - val_acc: 0.8480\n",
      "Epoch 338/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1025 - val_acc: 0.8526\n",
      "Epoch 339/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1012 - val_acc: 0.8537\n",
      "Epoch 340/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0949 - acc: 0.8475 - val_loss: 0.1038 - val_acc: 0.8480\n",
      "Epoch 341/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 342/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1057 - val_acc: 0.8470\n",
      "Epoch 343/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1037 - val_acc: 0.8480\n",
      "Epoch 344/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1027 - val_acc: 0.8526\n",
      "Epoch 345/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1059 - val_acc: 0.8462\n",
      "Epoch 346/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 347/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1061 - val_acc: 0.8462\n",
      "Epoch 348/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1058 - val_acc: 0.8462\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1054 - val_acc: 0.8472\n",
      "Epoch 350/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1055 - val_acc: 0.8464\n",
      "Epoch 351/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1081 - val_acc: 0.8439\n",
      "Epoch 352/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1036 - val_acc: 0.8481\n",
      "Epoch 353/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1039 - val_acc: 0.8478\n",
      "Epoch 354/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1042 - val_acc: 0.8473\n",
      "Epoch 355/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 356/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1043 - val_acc: 0.8473\n",
      "Epoch 357/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1043 - val_acc: 0.8473\n",
      "Epoch 358/500\n",
      "10500/10500 [==============================] - 9s 880us/step - loss: 0.0949 - acc: 0.8474 - val_loss: 0.1061 - val_acc: 0.8464\n",
      "Epoch 359/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1044 - val_acc: 0.8473\n",
      "Epoch 360/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1062 - val_acc: 0.8462\n",
      "Epoch 361/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1040 - val_acc: 0.8473\n",
      "Epoch 362/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1058 - val_acc: 0.8462\n",
      "Epoch 363/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1077 - val_acc: 0.8440\n",
      "Epoch 364/500\n",
      "10500/10500 [==============================] - 9s 877us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1057 - val_acc: 0.8462\n",
      "Epoch 365/500\n",
      "10500/10500 [==============================] - 9s 878us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1033 - val_acc: 0.8492\n",
      "Epoch 366/500\n",
      "10500/10500 [==============================] - 10s 907us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1042 - val_acc: 0.8478\n",
      "Epoch 367/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8473 - val_loss: 0.1081 - val_acc: 0.8439\n",
      "Epoch 368/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1049 - val_acc: 0.8472\n",
      "Epoch 369/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1063 - val_acc: 0.8448\n",
      "Epoch 370/500\n",
      "10500/10500 [==============================] - 9s 876us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1045 - val_acc: 0.8472\n",
      "Epoch 371/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 372/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1050 - val_acc: 0.8472\n",
      "Epoch 373/500\n",
      "10500/10500 [==============================] - 9s 883us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1071 - val_acc: 0.8440\n",
      "Epoch 374/500\n",
      "10500/10500 [==============================] - 9s 884us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1070 - val_acc: 0.8440\n",
      "Epoch 375/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1056 - val_acc: 0.8464\n",
      "Epoch 376/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1057 - val_acc: 0.8462\n",
      "Epoch 377/500\n",
      "10500/10500 [==============================] - 9s 881us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1067 - val_acc: 0.8448\n",
      "Epoch 378/500\n",
      "10500/10500 [==============================] - 9s 879us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 379/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1043 - val_acc: 0.8473\n",
      "Epoch 380/500\n",
      "10500/10500 [==============================] - 9s 882us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1046 - val_acc: 0.8473\n",
      "Epoch 381/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1040 - val_acc: 0.8473\n",
      "Epoch 382/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1066 - val_acc: 0.8447\n",
      "Epoch 383/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1061 - val_acc: 0.8462\n",
      "Epoch 384/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1064 - val_acc: 0.8448\n",
      "Epoch 385/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1064 - val_acc: 0.8462\n",
      "Epoch 386/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1050 - val_acc: 0.8464\n",
      "Epoch 387/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1063 - val_acc: 0.8462\n",
      "Epoch 388/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1047 - val_acc: 0.8472\n",
      "Epoch 389/500\n",
      "10500/10500 [==============================] - 9s 885us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1056 - val_acc: 0.8464\n",
      "Epoch 390/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1066 - val_acc: 0.8462\n",
      "Epoch 391/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1042 - val_acc: 0.8473\n",
      "Epoch 392/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1042 - val_acc: 0.8473\n",
      "Epoch 393/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1059 - val_acc: 0.8462\n",
      "Epoch 394/500\n",
      "10500/10500 [==============================] - 10s 922us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1067 - val_acc: 0.8448\n",
      "Epoch 395/500\n",
      "10500/10500 [==============================] - 10s 928us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 396/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1037 - val_acc: 0.8478\n",
      "Epoch 397/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1071 - val_acc: 0.8440\n",
      "Epoch 398/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1044 - val_acc: 0.8473\n",
      "Epoch 399/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1036 - val_acc: 0.8481\n",
      "Epoch 400/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1054 - val_acc: 0.8464\n",
      "Epoch 401/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1058 - val_acc: 0.8462\n",
      "Epoch 402/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1050 - val_acc: 0.8464\n",
      "Epoch 403/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1033 - val_acc: 0.8481\n",
      "Epoch 404/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1031 - val_acc: 0.8492\n",
      "Epoch 405/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1060 - val_acc: 0.8462\n",
      "Epoch 406/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1063 - val_acc: 0.8462\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1076 - val_acc: 0.8440\n",
      "Epoch 408/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 409/500\n",
      "10500/10500 [==============================] - 9s 887us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1034 - val_acc: 0.8478\n",
      "Epoch 410/500\n",
      "10500/10500 [==============================] - 9s 886us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1070 - val_acc: 0.8443\n",
      "Epoch 411/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1035 - val_acc: 0.8478\n",
      "Epoch 412/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1056 - val_acc: 0.8462\n",
      "Epoch 413/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1071 - val_acc: 0.8440\n",
      "Epoch 414/500\n",
      "10500/10500 [==============================] - 10s 965us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1032 - val_acc: 0.8481\n",
      "Epoch 415/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1042 - val_acc: 0.8473\n",
      "Epoch 416/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1050 - val_acc: 0.8464\n",
      "Epoch 417/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 418/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1037 - val_acc: 0.8478\n",
      "Epoch 419/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1057 - val_acc: 0.8464\n",
      "Epoch 420/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1058 - val_acc: 0.8464\n",
      "Epoch 421/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1066 - val_acc: 0.8443\n",
      "Epoch 422/500\n",
      "10500/10500 [==============================] - 9s 889us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1044 - val_acc: 0.8473\n",
      "Epoch 423/500\n",
      "10500/10500 [==============================] - 9s 888us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1054 - val_acc: 0.8464\n",
      "Epoch 424/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1037 - val_acc: 0.8473\n",
      "Epoch 425/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8470 - val_loss: 0.1064 - val_acc: 0.8448\n",
      "Epoch 426/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1066 - val_acc: 0.8443\n",
      "Epoch 427/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1040 - val_acc: 0.8473\n",
      "Epoch 428/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1068 - val_acc: 0.8443\n",
      "Epoch 429/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1027 - val_acc: 0.8492\n",
      "Epoch 430/500\n",
      "10500/10500 [==============================] - 10s 905us/step - loss: 0.0949 - acc: 0.8472 - val_loss: 0.1044 - val_acc: 0.8473\n",
      "Epoch 431/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1072 - val_acc: 0.8440\n",
      "Epoch 432/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1085 - val_acc: 0.8430\n",
      "Epoch 433/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1060 - val_acc: 0.8462\n",
      "Epoch 434/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1026 - val_acc: 0.8493\n",
      "Epoch 435/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 436/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1045 - val_acc: 0.8473\n",
      "Epoch 437/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1034 - val_acc: 0.8481\n",
      "Epoch 438/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1047 - val_acc: 0.8472\n",
      "Epoch 439/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1048 - val_acc: 0.8472\n",
      "Epoch 440/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1037 - val_acc: 0.8478\n",
      "Epoch 441/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 442/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1052 - val_acc: 0.8472\n",
      "Epoch 443/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1068 - val_acc: 0.8443\n",
      "Epoch 444/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1068 - val_acc: 0.8443\n",
      "Epoch 445/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1050 - val_acc: 0.8464\n",
      "Epoch 446/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1037 - val_acc: 0.8473\n",
      "Epoch 447/500\n",
      "10500/10500 [==============================] - 10s 912us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1045 - val_acc: 0.8472\n",
      "Epoch 448/500\n",
      "10500/10500 [==============================] - 10s 918us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1048 - val_acc: 0.8464\n",
      "Epoch 449/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1069 - val_acc: 0.8443\n",
      "Epoch 450/500\n",
      "10500/10500 [==============================] - 10s 909us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1050 - val_acc: 0.8464\n",
      "Epoch 451/500\n",
      "10500/10500 [==============================] - 10s 905us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1062 - val_acc: 0.8448\n",
      "Epoch 452/500\n",
      "10500/10500 [==============================] - 10s 912us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1059 - val_acc: 0.8464\n",
      "Epoch 453/500\n",
      "10500/10500 [==============================] - 10s 920us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1065 - val_acc: 0.8448\n",
      "Epoch 454/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0949 - acc: 0.8464 - val_loss: 0.1028 - val_acc: 0.8492\n",
      "Epoch 455/500\n",
      "10500/10500 [==============================] - 10s 938us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1049 - val_acc: 0.8464\n",
      "Epoch 456/500\n",
      "10500/10500 [==============================] - 10s 918us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1054 - val_acc: 0.8464\n",
      "Epoch 457/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1066 - val_acc: 0.8448\n",
      "Epoch 458/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1045 - val_acc: 0.8473\n",
      "Epoch 459/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1036 - val_acc: 0.8478\n",
      "Epoch 460/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1031 - val_acc: 0.8481\n",
      "Epoch 461/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1062 - val_acc: 0.8462\n",
      "Epoch 462/500\n",
      "10500/10500 [==============================] - 9s 891us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1049 - val_acc: 0.8465\n",
      "Epoch 463/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1057 - val_acc: 0.8464\n",
      "Epoch 464/500\n",
      "10500/10500 [==============================] - 9s 904us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1069 - val_acc: 0.8440\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1065 - val_acc: 0.8448\n",
      "Epoch 466/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1061 - val_acc: 0.8462\n",
      "Epoch 467/500\n",
      "10500/10500 [==============================] - 9s 898us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1043 - val_acc: 0.8473\n",
      "Epoch 468/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1024 - val_acc: 0.8493\n",
      "Epoch 469/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8471 - val_loss: 0.1075 - val_acc: 0.8440\n",
      "Epoch 470/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1058 - val_acc: 0.8448\n",
      "Epoch 471/500\n",
      "10500/10500 [==============================] - 9s 894us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1041 - val_acc: 0.8473\n",
      "Epoch 472/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1071 - val_acc: 0.8440\n",
      "Epoch 473/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1046 - val_acc: 0.8472\n",
      "Epoch 474/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1057 - val_acc: 0.8464\n",
      "Epoch 475/500\n",
      "10500/10500 [==============================] - 9s 893us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1045 - val_acc: 0.8473\n",
      "Epoch 476/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1044 - val_acc: 0.8473\n",
      "Epoch 477/500\n",
      "10500/10500 [==============================] - 10s 912us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1060 - val_acc: 0.8462\n",
      "Epoch 478/500\n",
      "10500/10500 [==============================] - 10s 921us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1073 - val_acc: 0.8440\n",
      "Epoch 479/500\n",
      "10500/10500 [==============================] - 10s 917us/step - loss: 0.0949 - acc: 0.8463 - val_loss: 0.1025 - val_acc: 0.8492\n",
      "Epoch 480/500\n",
      "10500/10500 [==============================] - 10s 919us/step - loss: 0.0949 - acc: 0.8469 - val_loss: 0.1051 - val_acc: 0.8464\n",
      "Epoch 481/500\n",
      "10500/10500 [==============================] - 10s 914us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1068 - val_acc: 0.8443\n",
      "Epoch 482/500\n",
      "10500/10500 [==============================] - 10s 928us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1052 - val_acc: 0.8464\n",
      "Epoch 483/500\n",
      "10500/10500 [==============================] - 10s 935us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1052 - val_acc: 0.8464\n",
      "Epoch 484/500\n",
      "10500/10500 [==============================] - 10s 923us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1057 - val_acc: 0.8464\n",
      "Epoch 485/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1036 - val_acc: 0.8473\n",
      "Epoch 486/500\n",
      "10500/10500 [==============================] - 9s 896us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1047 - val_acc: 0.8464\n",
      "Epoch 487/500\n",
      "10500/10500 [==============================] - 9s 890us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1043 - val_acc: 0.8473\n",
      "Epoch 488/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1064 - val_acc: 0.8448\n",
      "Epoch 489/500\n",
      "10500/10500 [==============================] - 9s 902us/step - loss: 0.0949 - acc: 0.8464 - val_loss: 0.1039 - val_acc: 0.8473\n",
      "Epoch 490/500\n",
      "10500/10500 [==============================] - 10s 973us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1060 - val_acc: 0.8462\n",
      "Epoch 491/500\n",
      "10500/10500 [==============================] - 10s 910us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1067 - val_acc: 0.8443\n",
      "Epoch 492/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1054 - val_acc: 0.8464\n",
      "Epoch 493/500\n",
      "10500/10500 [==============================] - 9s 900us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1080 - val_acc: 0.8430\n",
      "Epoch 494/500\n",
      "10500/10500 [==============================] - 9s 897us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1087 - val_acc: 0.8424\n",
      "Epoch 495/500\n",
      "10500/10500 [==============================] - 9s 892us/step - loss: 0.0949 - acc: 0.8464 - val_loss: 0.1056 - val_acc: 0.8464\n",
      "Epoch 496/500\n",
      "10500/10500 [==============================] - 10s 911us/step - loss: 0.0949 - acc: 0.8465 - val_loss: 0.1049 - val_acc: 0.8465\n",
      "Epoch 497/500\n",
      "10500/10500 [==============================] - 10s 908us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1071 - val_acc: 0.8440\n",
      "Epoch 498/500\n",
      "10500/10500 [==============================] - 9s 899us/step - loss: 0.0949 - acc: 0.8466 - val_loss: 0.1053 - val_acc: 0.8464\n",
      "Epoch 499/500\n",
      "10500/10500 [==============================] - 9s 895us/step - loss: 0.0949 - acc: 0.8467 - val_loss: 0.1053 - val_acc: 0.8464\n",
      "Epoch 500/500\n",
      "10500/10500 [==============================] - 9s 903us/step - loss: 0.0949 - acc: 0.8468 - val_loss: 0.1072 - val_acc: 0.8440\n",
      "5250/5250 [==============================] - 5s 917us/step - loss: 0.1072 - acc: 0.8440\n",
      "\n",
      "Test Accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x_train],y=y_train, validation_data=([x_test], y_test), \n",
    "                    epochs=epochs, batch_size=batchs, class_weight=class_weights)\n",
    "\n",
    "model.save_weights(r'weightANDlearningcurve/GeoIModule_model_3layer.h5')\n",
    "eval_model=[]\n",
    "eval_model.append(model.evaluate([x_test], y_test)[1])\n",
    "print(\"\\nTest Accuracy: %.4f\" % eval_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796c0df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='r')\n",
    "plt.plot(history.history['val_loss'],color='g')\n",
    "plt.plot(history.history['acc'],color='b')\n",
    "plt.plot(history.history['val_acc'],color='k')\n",
    "plt.title('T1: I Frame module learning curve (Geometry)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left',bbox_to_anchor=(0,-0.3))\n",
    "plt.savefig('FeaturesPlots/I_GeoTrainingCurve.jpg', bbox_inches='tight', dpi=1280)\n",
    "plt.show()\n",
    "\n",
    "import pickle\n",
    "with open('weightANDlearningcurve/GeoIModule_history.txt', 'wb') as file_txt:\n",
    "    pickle.dump(history.history, file_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e8dc35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "g_weight1: \n",
      "0.6204135,-0.0033143784,-0.46809793,-0.48769483,-0.43500265,-0.46228862,0.53266656,-0.08642557,0.006234025,0.019045802,0.42389688,-0.040039994,-0.46745688,-0.5922589,-0.42618778,-0.52435696,0.6982205,-0.061058495,0.030641833,0.013372389,1.6147555,-0.045742925,-0.56477785,-0.39006177,-0.59300745,-0.4267901,1.6327562,-0.9566185,0.044295337,0.0053097475,\n",
      "\n",
      "g_bias1: \n",
      "0.007395363,-0.04122607,0.9725882,0.99157387,0.9288985,0.94253135,0.021805132,0.7299237,-0.0746833,-0.07544615,\n",
      "\n",
      "g_weight2: \n",
      "-1.898781,-0.8346444,1.2894796,-1.4912176,1.4373511,-0.11940807,0.06989383,0.08358438,-0.063021,0.053709157,1.6494349,3.4347556,-0.9816182,1.1113468,-0.9498174,1.5140239,3.6476634,-0.7178802,0.86918163,-0.61173844,1.745992,3.268361,-1.0131794,1.1418445,-0.9769755,1.4974976,3.5412936,-0.70559436,1.0097489,-0.75205415,-1.9995363,-0.9150886,1.26214,-1.4402719,1.0642905,1.8620082,0.7185871,-2.2758718,2.1377661,-1.933269,-0.022734718,0.057994064,0.029444396,-0.03444635,0.08123057,-0.054112207,-0.01166402,0.06323806,-0.05393774,0.023760675,\n",
      "\n",
      "g_bias2: \n",
      "-0.22579643,0.5758123,-0.008848444,-0.07719733,-0.08820179,\n",
      "\n",
      "a_weight3: \n",
      "-4.122439,-2.8610075,2.189674,-3.310542,2.1722171,\n",
      "\n",
      "a_bias3: \n",
      "0.031202246,"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "g_weight1=model.get_weights()[0]\n",
    "g_bias1=model.get_weights()[1]\n",
    "g_weight2=model.get_weights()[2]\n",
    "g_bias2=model.get_weights()[3]\n",
    "g_weight3=model.get_weights()[4]\n",
    "g_bias3=model.get_weights()[5]\n",
    "\n",
    "\n",
    "print(\"\\ng_weight1: \")\n",
    "for a in g_weight1:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\ng_bias1: \")\n",
    "for a in g_bias1:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "print(\"\\n\\ng_weight2: \")\n",
    "for a in g_weight2:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\ng_bias2: \")\n",
    "for a in g_bias2:\n",
    "        print(a,end=\",\")\n",
    "\n",
    "print(\"\\n\\na_weight3: \")\n",
    "for a in g_weight3:\n",
    "    for b in a:\n",
    "        print(b,end=\",\")\n",
    "        \n",
    "print(\"\\n\\na_bias3: \")\n",
    "for a in g_bias3:\n",
    "        print(a,end=\",\")\n",
    "        \n",
    "# a_weight1=model.get_layer(index=0).get_weights()\n",
    "# a_weight2=model.get_layer(index=1).get_weights()\n",
    "        \n",
    "# print(a_weight1)\n",
    "# print(a_weight2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
